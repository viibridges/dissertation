Hold-Geoffroy \etal~\cite{hold2017perceptual}
improve~\cite{workman2016horizon}'s results by using deeper networks,
and introduce a new perceptual measure for horizon line detection.
Unlike the previous work that mainly focus on horizon line detection,
Zhang \etal~\cite{zhang2018dominant} propose to detect the dominant
vanishing point using deep neural networks.

\brief{
Geometric information can help training neural network to extract
high-level information.
}

\todo{re-edit}
The use of overhead imagery has been proved useful for image
understanding.
Several methods have been recently proposed to jointly reason about
co-located aerial and ground image pairs. Luo
\etal~\cite{luo2008event} demonstrate that aerial imagery can aid
in recognizing the visual content of a geo-tagged ground image.
M{\'a}ttyus \etal~\cite{mattyus2016hd} perform joint inference over
monocular aerial imagery and stereo ground images for fine-grained
road segmentation. Wegner \etal~\cite{wegner2016cataloging} build a
map of street trees. Given the horizon line and the camera intrinsics,
Ghouaiel and Lef{\`e}vre~\cite{ghouaiel2016coupling} transform
geo-tagged ground-level panoramas to a top-down view to enable
comparisons with aerial imagery for the task of change detection.
Recent work on cross-view image
geolocalization~\cite{lin2013cross,lin2015learning,workman2015geocnn,workman2015wide}
 has shown that convolutional neural
networks are capable of extracting features from aerial imagery
that can be matched to features extracted from ground imagery.
Vo \etal~\cite{vo2016localizing} extend this line of work,
demonstrating improved geolocalization performance by applying an
auxiliary loss function to regress the ground-level camera orientation
with respect to the aerial image. To our knowledge, our work is the
first work to explore predicting the semantic layout of a ground
image from an aerial image.


The study of understanding images has been around for half a century.
A well known anecdote in computer vision community happened in 1960s,
when the MIT professor Dr. Marvin Minsky assigned a summer programming
project to his undergraduates, to recognize objects in a
scene~\cite{boden2006mind}. 
%
Similar to the story of the famous ``Four Color Conjecture'', where
one of the world's renowned mathematicians Dr. Hermann Minkowski
claimed in his class that he was able to solve it before the class
ends.  
However, Not until one hundred years later since it was first
proposed, the ``Four Color Conjecture'' has been stamped as theorem by
the continuous efforts of several generations of talented
mathematicians.  While on the other side, Dr. Marvin Minsky's summer
program still remains open.


To achieve this
goal, researchers adopt a divide-and-conquer strategy, that is
dividing image understanding into various sub-problems like object
recognition, semantic segmentation, and pose estimation \etc.  During
past decades, a lot of methods are developed to solve these
sub-problems. Many of them adopted a bottom-up (\todo{citations})
workflow, where basic level cues play important roles
(\todo{examples}). Among these basic cues, camera geometry is
particularly useful for some computer vision tasks like facade
detection, indoor layout estimation~\cite{ren2016coarse}.
