\chapter{Summary}
\label{chap:discussion}

The goal of geo-calibration is to learn the camera pose, location and
the time when the image was captured.
Our thesis focused on developing deep geo-calibration algorithms for
image understanding.
Compared to previous work, our approaches output probabilistic
predictions that handle the uncertainty of the scene
better. Furthermore, we show that
learning to geo-calibrate a camera allows us to implicitly learn to
understand the content of the scene.


In \chapref{mcmc}, we proposed a flexible model to compute the
probability over geo-calibration parameters. We defined a score
function in the space of geo-calibration parameters, to measure how
well the geo-calibration parameters are able to describe the content
of the input image.
The score function is a summation of a series of weighted
constraint functions. It is proportional to the probability density
function (PDF) of the distribution over the geo-calibration parameter setting.
Since the analytic solution to the
integral of the score function does not exist, we approximated the
PDF using the MCMC method. Our model is flexible such that one can apply
any kind and any number of constraint functions.
We also demonstrated in our experiments that the score function with more
constraint functions yields more accurate predictions.

In \chapref{fasthorizon}, we developed a constraint function for the
camera pose. Since the camera roll and pitch angles can be derived from
the horizon line position, our algorithm focuses on identifying the
horizon line from the input image.
Compared to the previous work, which applies bottom-up
approaches where the horizon line is estimated after finding vanishing
points, we proposed a novel horizon-first approach where
identifying possible horizon lines happens before detecting vanishing
points. 
Firstly, we trained a CNN to estimate the probability distribution
over the horizon line. Then we sampled horizon line candidates from
it. For each horizon candidate, we detected likely
vanishing points on it. Unlike the previous work which searches for
vanishing points on the 2D image frame, our method is able to
accelerate this process by reducing the searching space to
1D (a line). The probability of the horizon line is measured by how
convincing the vanishing points are found on it. 

In \chapref{whenwhere}, we developed the constraint function for 
the image capture time and the camera location. 
We trained a CNN on a large dataset to predict the discrete
probabilities over the capture time and the camera location given the
input image, as well as to learn a geo-temporal representation
of the image.
Unlike most full supervision methods which require tedious work for 
annotation collection, our training dataset consists of millions of webcam
frames and smart phone photos with free time/location tags.
In the experiments, we demonstrated that learning to geo-calibrate the
camera helps learn useful image representations for image understanding.

In \chapref{crosstransf}, we exploited overhead imagery to construct
the constraint function for the camera orientation and location.
We trained a CNN to estimate the semantic layout of the
ground-view image from the overhead image. During training, the CNN
learns the pixel-to-pixel correspondences from the aerial image to the
ground image. Then it projects the semantic layout of the overhead
image to the ground view according to the learned correspondences.
When computing the output of the constraint function, we feed the
aerial image of the given location and orientation to the network. By
comparing the aerial-to-ground layout with the layout computed from
the ground image, we measure the consistency between these two and use
the consistency value as the output of the constraint function. 
In our experiments, we also demonstrated the efficiency of our method
for pre-training CNNs for aerial image segmentation.

This thesis proposed a flexible probabilistic framework for image
geo-calibration. The key to the success of this framework is to find
constraint functions that can accurately model the relationship between
geo-calibration parameters and the content of the image. 
We developed constraint functions for different sets of parameters to
fit in the framework. 
Furthermore, we also showed that learning to geo-calibrate cameras helps
learning useful features for image understanding. 
%
There are several possible future research directions for extending
this work. For example, like aerial imagery, map data also
provides rich information about the environment from the top-view
perspective. In \chapref{crosstransf}, we can incorporate map data
as top-view imagery during training.
%
Another future work direction is to use Bayesian neural networks
(BNNs). Bayesian neural networks have drawn a lot
of attentions in recent years. The probabilistic nature of BNNs makes
them excellent tools to model uncertainties. We can replace CNNs
with BNNs in our algorithms to achieve better performances.
Overall, we hope our work can provide new ways for geo-calibration and
image feature learning.
