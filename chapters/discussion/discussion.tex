\chapter{Discussion}
\label{chap:discussion}

The goal of geo-calibration is to learn the camera pose, location and
the time when the image was captured.
Our thesis focused on developing deep geo-calibration algorithms for
image understanding.
Compared to previous work, our approaches output probabilistic
predictions that are able to handle the uncertainty of the scene
better. Furthermore, we also show that
learning to geo-calibrate a camera allows us to implicitly learn to
understand the content of the scene.


In \chapref{mcmc}, we proposed a flexible model to compute the
probability over all geo-calibration parameters. In the high
dimensional space of geo-calibration parameters, we defined an score
function for every point in that space, to measure how well the
geo-calibration parameters match the content of the input image. The
score function is defined as a weighted summation of a series of
constraint functions, and is proportional to the probability density
function of the distribution. Since xxx is computationally
intractable, in order to xxx, we approximated the probability
density function using MCMC method.

In \chapref{fasthorizon}, we focused on constraint function for the
camera pose. Assuming the focal length is known, the camera roll and
pitch angle can be derived from the horizon line position. Our
algorithm identifies the horizon line from an input image that
satisfied the Manhattan world assumption.
Compared to most previous work which applies a bottom-up approach by
fitting the horizon line from the vanishing points, we proposed a
novel horizon-first approach to identify the horizon line.
First we trained a CNN to estimate the distribution of the horizon
line. Then we sample horizon line candidates from the horizon line
distribution. For each horizon candidate, we find the possible
vanishing points on it. Compared to previous work which searches for 
vanishing points on image frame, our method accelerate the searching
process by carrying it out in the 1D space. The probability of the
horizon candidate to be the real horizon line is measured by how many
and good vanishing points found on it. 

In \chapref{whenwhere}, we constructed the constraint function for 
the image capture time and the camera location. In order to achieve
this goal, we trained a CNN on a large dataset that consists of
millions webcam frames and smart phone photos. The network takes image
as input and output the discrete probability over location and time.
In this work, we took the advantage that geo-tagged and
temporal-tagged images are common nowadays to build the training set.
We demonstrate that geo-calibrating the camera helps learn image
representations useful for image understanding.

In \chapref{crosstransf}, we exploit overhead imagery to construct
the constraint function for the camera orientation and location.
We trained a CNN that can estimate the semantic layout of the ground
view image from the overhead image. During training, we learn the
pixel-to-pixel correspondences from the aerial image to the ground. We
project the semantic layout the of the overhead image to the ground
view with the learned correspondence.
When computing the output of the constraint function, we feed the
aerial image of the gien location and orientation to the network. By
comparing the aerial-to-ground with the real layout of the ground
image, we measure the consistency between the two and use
it as the value of our constraint function.
We also demonstrate the efficiency of our method for CNN pre-training
for aerial image segmentation.

This thesis proposed a probabilistic model for image
geo-calibration.
The key to the success of this model is to find constraint
functions that describe the relationship between geo-calibration
parameters and the image content. We developed constraint
functions for different set of parameters that can fit to the model.
Furthermore, we also show that learning to geo-calibrate cameras helps learning
useful features for image understanding.
There are several possible future research directions for extending
this work, including: exploiting map data in cross-view learning,
replacing the CNN networks in our algorithms with Bayesian neural
networks (BNNs).
Overall, we hope our work can provide new ways for geo-calibration and
pre-task training.
