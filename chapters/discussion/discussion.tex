\chapter{Discussion}
\label{chap:discussion}

The goal of geo-calibration is to learn the camera pose, location and
the time when the image was captured.
Our thesis focused on developing deep geo-calibration algorithms for
image understanding.
Compared to previous work, our approaches give
probabilistic outputs that are more flexible and are able to handle
the uncertainty of the scene better.

In \chapref{mcmc}, we proposed a flexible model to compute the
probability over all geo-calibration parameters. In the high
dimensional space of geo-calibration parameters, we defined an score
function for every point in that space, to measure how well the
geo-calibration parameters match the content of the input image. The
score function is defined as a weighted summation of a series of
constraint functions, and is proportional to the probability density
function of the distribution. Since xxx is computationally
intractable, in order to xxx, we approximated the probability
density function using MCMC method.
\todo{why grid method doesn't work here}
\todo{evaluation}

In \chapref{fasthorizon}, we focused on constraint function for the
camera pose. Assuming the focal length is known, the camera roll and
pitch angle can be derived from the horizon line position. Our
algorithm identifies the horizon line from an input image that
satisfied the Manhattan world assumption.
Compared to most previous work which applies a bottom-up approach by
fitting the horizon line from the vanishing points, we proposed a
novel horizon-first approach to identify the horizon line.
First we trained a CNN to estimate the distribution of the horizon
line. Then we sample horizon line candidates from the horizon line
distribution. For each horizon candidate, we find the possible
vanishing points on it. Compared to previous work which searches for 
vanishing points on image frame, our method accelerate the searching
process by carrying it out in the 1D space. The probability of the
horizon candidate to be the real horizon line is measured by how many
and good vanishing points found on it. 

In \chapref{whenwhere}, we constructed the constraint function for 
the image capture time and the camera location. In order to achieve
this goal, we trained a CNN on a large dataset that consists of
millions webcam frames and smart phone photos. The network takes image
as input and output the discrete probability over location and time.
In this work, we took the advantage that geo-tagged and
temporal-tagged images are common nowadays, to build our training set.
We demonstrate that geo-calibrating the camera helps learn image
representations useful for image understanding.

In \chapref{crosstransf}, we exploit the overhead image to construct
the constraint function for the camera orientation and location.
